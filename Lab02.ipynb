{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy, math\n",
    "documentsFilename = 'estadao_noticias_eleicao.csv'\n",
    "gabaritoFilename = 'gabarito.csv'\n",
    "data = pd.read_csv(documentsFilename)\n",
    "gabarito = pd.read_csv(gabaritoFilename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to print topFive of documents\n",
    "def returnTopFive(topFive):\n",
    "    print \"Top five documents\"\n",
    "    returnArray = []\n",
    "    for document in sorted(topFive, key = topFive.get, reverse=True):\n",
    "        print \"Document: \" + str(document) + \", frequence: \" + str(topFive[document])    \n",
    "        returnArray.append(document)\n",
    "    print returnArray\n",
    "    return returnArray\n",
    "\n",
    "#Function to verify if element 's' is nan    \n",
    "def is_nan(s):\n",
    "    try:\n",
    "        float(s)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to search with binary method\n",
    "def searchBinary(query):\n",
    "    searchWords = query.split(\" \")\n",
    "    #The top five document by higher frequences \n",
    "    topFive = {}\n",
    "    for i in range(len(data.values)):\n",
    "        #Get frequence of document i\n",
    "        documentID, frequence = frequenceBinary(searchWords, data.values[i]);\n",
    "        \n",
    "        #Add document and frequence in topFive dictionary\n",
    "        if(len(topFive) < 5):\n",
    "            topFive[documentID]= frequence\n",
    "        else:\n",
    "            minKey = None\n",
    "            for j in topFive.keys():\n",
    "                if(frequence > topFive[j]):\n",
    "                    if(minKey == None or topFive[j] < topFive[minKey]):\n",
    "                        minKey = j\n",
    "            if(minKey != None):\n",
    "                topFive[documentID] = frequence;\n",
    "                del topFive[minKey]\n",
    "    \n",
    "    return returnTopFive(topFive)\n",
    "        \n",
    "#Function to calculate the frequency of query words in the document\n",
    "def frequenceBinary(query, document):\n",
    "    frequenceBinary = {}\n",
    "    if(is_nan(document[1])):\n",
    "        document[1] = \"\"\n",
    "    if(is_nan(document[2])):\n",
    "        document[2] = \"\"\n",
    "    if(is_nan(document[3])):\n",
    "        document[3] = \"\"\n",
    "    documentWords = document[1].split(\" \") + document[2].split(\" \") + document[3].split(\" \")\n",
    "    \n",
    "    for q in query:\n",
    "        #Iterate on all document words\n",
    "        for word in documentWords:\n",
    "            if(q.lower() == word.lower()):\n",
    "                if(q not in frequenceBinary):\n",
    "                    frequenceBinary[q] = 1\n",
    "                    break\n",
    "    frequence = 0\n",
    "    for freq in frequenceBinary:\n",
    "        frequence += frequenceBinary[freq]\n",
    "    \n",
    "    return document[5], frequence\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to search with TF method \n",
    "def searchTF(query):\n",
    "    searchWords = query.split(\" \")\n",
    "    #The top five document by higher frequences \n",
    "    topFive = {}\n",
    "    for i in range(len(data.values)):\n",
    "        #Get frequence of document i\n",
    "        documentID, frequence = frequenceTF(searchWords, data.values[i]);\n",
    "        \n",
    "        #Add document and frequence in topFive dictionary\n",
    "        if(len(topFive) < 5):\n",
    "            topFive[documentID]= frequence\n",
    "        else:\n",
    "            minKey = None\n",
    "            for j in topFive.keys():\n",
    "                if(frequence > topFive[j]):\n",
    "                    if(minKey == None or topFive[j] < topFive[minKey]):\n",
    "                        minKey = j\n",
    "            if(minKey != None):\n",
    "                topFive[documentID] = frequence;\n",
    "                del topFive[minKey]\n",
    "    \n",
    "    return returnTopFive(topFive)\n",
    "        \n",
    "#Function to calculate the frequency of query words in the document\n",
    "def frequenceTF(query, document):\n",
    "    frequence = 0\n",
    "    if(is_nan(document[1])):\n",
    "        document[1] = \"\"\n",
    "    if(is_nan(document[2])):\n",
    "        document[2] = \"\"\n",
    "    if(is_nan(document[3])):\n",
    "        document[3] = \"\"\n",
    "    documentWords = document[1].split(\" \") + document[2].split(\" \") + document[3].split(\" \")\n",
    "    \n",
    "    #Iterate on all document words\n",
    "    for word in documentWords:\n",
    "        for q in query:\n",
    "            if(q.lower() == word.lower()):\n",
    "                frequence += 1\n",
    "    \n",
    "    return document[5], frequence\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to search with TF method \n",
    "def searchTF_IDF(query):\n",
    "    searchWords = query.split(\" \")\n",
    "    \n",
    "    #Number of documents in file \"data\"\n",
    "    numberOfDocs = len(data.values)\n",
    "    \n",
    "    #The top five document by higher frequences \n",
    "    topFive = {}\n",
    "    \n",
    "    #Calculate the number of documents that query words appear\n",
    "    dictDocsFrequence = {}\n",
    "    for i in range(len(data.values)):\n",
    "        dictDocsFrequence = IDF(searchWords, data.values[i], dictDocsFrequence)\n",
    "    \n",
    "    #Calculate IDF of query words\n",
    "    dictIDF = {}\n",
    "    for i in dictDocsFrequence.keys(): \n",
    "        dictIDF[i] = math.log10((numberOfDocs + 1) / dictDocsFrequence[i])\n",
    "    \n",
    "    #Iterate in all documents to calculate frequence of query words\n",
    "    for i in range(len(data.values)):\n",
    "        #Get frequence of document i\n",
    "        documentID, frequence = frequenceTF_IDF(searchWords, data.values[i], dictIDF);\n",
    "        \n",
    "        #Add document and frequence in topFive dictionary\n",
    "        if(len(topFive) < 5):\n",
    "            topFive[documentID]= frequence\n",
    "        else:\n",
    "            minKey = None\n",
    "            for j in topFive.keys():\n",
    "                if(frequence > topFive[j]):\n",
    "                    if(minKey == None or topFive[j] < topFive[minKey]):\n",
    "                        minKey = j\n",
    "            if(minKey != None):\n",
    "                topFive[documentID] = frequence;\n",
    "                del topFive[minKey]\n",
    "    \n",
    "    return returnTopFive(topFive)\n",
    "\n",
    "#Function to calculate IDF of query words\n",
    "def IDF(query, document, dictDocsFrequence):\n",
    "    #Verify if the line is nan\n",
    "    if(is_nan(document[1])):\n",
    "        document[1] = \" \"\n",
    "    if(is_nan(document[2])):\n",
    "        document[2] = \" \"\n",
    "    if(is_nan(document[3])):\n",
    "        document[3] = \" \"\n",
    "    \n",
    "    #All the words of documents in array\n",
    "    documentWords = document[1].split(\" \") + document[2].split(\" \") + document[3].split(\" \")\n",
    "    \n",
    "    #Iterate on query words\n",
    "    for wordQuery in query:\n",
    "        #Iterate on document words\n",
    "        for wordDocuments in documentWords:\n",
    "            #Verify if exist the word in document and change the frequence of documents\n",
    "            if(wordQuery.lower() == wordDocuments.lower()):\n",
    "                if(wordQuery in dictDocsFrequence):\n",
    "                    dictDocsFrequence[wordQuery] = dictDocsFrequence[wordQuery] + 1\n",
    "                    break\n",
    "                else:\n",
    "                    dictDocsFrequence[wordQuery] = 1\n",
    "                    break\n",
    "\n",
    "    return dictDocsFrequence\n",
    "\n",
    "#Function to calculate the frequency of query words in the document multiplicate \n",
    "def frequenceTF_IDF(query, document, dictIDF):\n",
    "    frequence = 0\n",
    "    \n",
    "    #Verify if the line is nan\n",
    "    if(is_nan(document[1])):\n",
    "        document[1] = \"\"\n",
    "    if(is_nan(document[2])):\n",
    "        document[2] = \"\"\n",
    "    if(is_nan(document[3])):\n",
    "        document[3] = \"\"\n",
    "        \n",
    "    #All the words of documents in array\n",
    "    documentWords = document[1].split(\" \") + document[2].split(\" \") + document[3].split(\" \")\n",
    "    \n",
    "    #Iterate on query words\n",
    "    for wordQuery in query:\n",
    "        frequenceWord = 0\n",
    "        #Iterate on document words\n",
    "        for wordDocument in documentWords:\n",
    "            if(wordQuery.lower() == wordDocument.lower()):\n",
    "                frequenceWord += 1\n",
    "        #Calculate frequence with IDF\n",
    "        frequence += frequenceWord * dictIDF[wordQuery]\n",
    "        \n",
    "    return document[5], frequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_BM25(query):\n",
    "    searchWords = query.split(\" \")\n",
    "    \n",
    "    #Number of documents in file \"data\"\n",
    "    numberOfDocs = len(data.values)\n",
    "    \n",
    "    #The top five document by higher frequences \n",
    "    topFive = {}\n",
    "    \n",
    "    #Calculate the number of documents that query words appear\n",
    "    dictDocsFrequence = {}\n",
    "    for i in range(len(data.values)):\n",
    "        dictDocsFrequence = IDF(searchWords, data.values[i], dictDocsFrequence)\n",
    "        \n",
    "    #Calculate IDF of query words\n",
    "    dictIDF = {}\n",
    "    for i in dictDocsFrequence.keys(): \n",
    "        dictIDF[i] = math.log10((numberOfDocs + 1) / dictDocsFrequence[i])\n",
    "    \n",
    "    #Iterate in all documents to calculate frequence of query words\n",
    "    for i in range(len(data.values)):\n",
    "        #Get frequence of document i\n",
    "        documentID, frequence = frequenceBM25(searchWords, data.values[i], dictIDF);\n",
    "        \n",
    "        #Add document and frequence in topFive dictionary\n",
    "        if(len(topFive) < 5):\n",
    "            topFive[documentID]= frequence\n",
    "        else:\n",
    "            minKey = None\n",
    "            for j in topFive.keys():\n",
    "                if(frequence > topFive[j]):\n",
    "                    if(minKey == None or topFive[j] < topFive[minKey]):\n",
    "                        minKey = j\n",
    "            if(minKey != None):\n",
    "                topFive[documentID] = frequence;\n",
    "                del topFive[minKey]\n",
    "    \n",
    "    return returnTopFive(topFive)\n",
    "    \n",
    "#Function to calculate IDF of query words\n",
    "def IDF(query, document, dictDocsFrequence):\n",
    "    #Verify if the line is nan\n",
    "    if(is_nan(document[1])):\n",
    "        document[1] = \" \"\n",
    "    if(is_nan(document[2])):\n",
    "        document[2] = \" \"\n",
    "    if(is_nan(document[3])):\n",
    "        document[3] = \" \"\n",
    "    \n",
    "    #All the words of documents in array\n",
    "    documentWords = document[1].split(\" \") + document[2].split(\" \") + document[3].split(\" \")\n",
    "    \n",
    "    #Iterate on query words\n",
    "    for wordQuery in query:\n",
    "        #Iterate on document words\n",
    "        for wordDocuments in documentWords:\n",
    "            #Verify if exist the word in document and change the frequence of documents\n",
    "            if(wordQuery.lower() == wordDocuments.lower()):\n",
    "                if(wordQuery in dictDocsFrequence):\n",
    "                    dictDocsFrequence[wordQuery] = dictDocsFrequence[wordQuery] + 1\n",
    "                    break\n",
    "                else:\n",
    "                    dictDocsFrequence[wordQuery] = 1\n",
    "                    break\n",
    "\n",
    "    return dictDocsFrequence\n",
    "\n",
    "#Function to calculate the frequency of query words in the document multiplicate \n",
    "def frequenceBM25(query, document, dictIDF):\n",
    "    frequence = 0\n",
    "    \n",
    "    #Verify if the line is nan\n",
    "    if(is_nan(document[1])):\n",
    "        document[1] = \"\"\n",
    "    if(is_nan(document[2])):\n",
    "        document[2] = \"\"\n",
    "    if(is_nan(document[3])):\n",
    "        document[3] = \"\"\n",
    "        \n",
    "    #All the words of documents in array\n",
    "    documentWords = document[1].split(\" \") + document[2].split(\" \") + document[3].split(\" \")\n",
    "    \n",
    "    #Iterate on query words\n",
    "    for wordQuery in query:\n",
    "        frequenceWord = 0\n",
    "        #Iterate on document words\n",
    "        for wordDocument in documentWords:\n",
    "            if(wordQuery.lower() == wordDocument.lower()):\n",
    "                frequenceWord += 1\n",
    "        #Calculate frequence with IDF\n",
    "        frequence += frequenceWord * dictIDF[wordQuery]\n",
    "        \n",
    "    return document[5], frequence\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apk(actual, predicted, k=10):\n",
    "    \"\"\"\n",
    "    Computes the average precision at k.\n",
    "    This function computes the average prescision at k between two lists of\n",
    "    items.\n",
    "    Parameters\n",
    "    ----------\n",
    "    actual : list\n",
    "             A list of elements that are to be predicted (order doesn't matter)\n",
    "    predicted : list\n",
    "                A list of predicted elements (order does matter)\n",
    "    k : int, optional\n",
    "        The maximum number of predicted elements\n",
    "    Returns\n",
    "    -------\n",
    "    score : double\n",
    "            The average precision at k over the input lists\n",
    "    \"\"\"\n",
    "    print predicted\n",
    "    print actual\n",
    "    print type(predicted)\n",
    "    print type(actual)\n",
    "    if len(predicted)>k:\n",
    "        predicted = predicted[:k]\n",
    "\n",
    "    score = 0.0\n",
    "    num_hits = 0.0\n",
    "\n",
    "    for i,p in enumerate(predicted):\n",
    "        if p in actual and p not in predicted[:i]:\n",
    "            num_hits += 1.0\n",
    "            score += num_hits / (i+1.0)\n",
    "\n",
    "    if not actual:\n",
    "        return 0.0\n",
    "\n",
    "    return score / min(len(actual), k)\n",
    "\n",
    "def mapk(actual, predicted, k=10):\n",
    "    \"\"\"\n",
    "    Computes the mean average precision at k.\n",
    "    This function computes the mean average prescision at k between two lists\n",
    "    of lists of items.\n",
    "    Parameters\n",
    "    ----------\n",
    "    actual : list\n",
    "             A list of lists of elements that are to be predicted \n",
    "             (order doesn't matter in the lists)\n",
    "    predicted : list\n",
    "                A list of lists of predicted elements\n",
    "                (order matters in the lists)\n",
    "    k : int, optional\n",
    "        The maximum number of predicted elements\n",
    "    Returns\n",
    "    -------\n",
    "    score : double\n",
    "            The mean average precision at k over the input lists\n",
    "    \"\"\"\n",
    "    print type(predicted)\n",
    "    print type(actual)\n",
    "    return numpy.mean([apk(a,p,k) for a,p in zip(actual, predicted)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top five documents\n",
      "Document: 69, frequence: 2\n",
      "Document: 102, frequence: 2\n",
      "Document: 7, frequence: 2\n",
      "Document: 111, frequence: 2\n",
      "Document: 92, frequence: 2\n",
      "[69, 102, 7, 111, 92]\n",
      "Top five documents\n",
      "Document: 2744, frequence: 31\n",
      "Document: 7, frequence: 27\n",
      "Document: 2112, frequence: 17\n",
      "Document: 2388, frequence: 17\n",
      "Document: 4931, frequence: 15\n",
      "[2744, 7, 2112, 2388, 4931]\n",
      "Top five documents\n",
      "Document: 2744, frequence: 19.1301175722\n",
      "Document: 7, frequence: 11.3938724518\n",
      "Document: 1917, frequence: 8.78690753572\n",
      "Document: 2112, frequence: 8.38357249516\n",
      "Document: 4931, frequence: 7.78151250384\n",
      "[2744, 7, 1917, 2112, 4931]\n",
      "<type 'list'>\n",
      "<type 'str'>\n",
      "69\n",
      "[\n",
      "<type 'int'>\n",
      "<type 'str'>\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'int' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-97-9e5124d81750>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mbusca_TF_IDF\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msearchTF_IDF\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"segundo turno\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmapk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgabarito\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbusca_binaria\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mmapk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgabarito\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbusca_TF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-96-a4dbb4e3454e>\u001b[0m in \u001b[0;36mmapk\u001b[0;34m(actual, predicted, k)\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactual\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mapk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactual\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-96-a4dbb4e3454e>\u001b[0m in \u001b[0;36mapk\u001b[0;34m(actual, predicted, k)\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactual\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredicted\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'int' has no len()"
     ]
    }
   ],
   "source": [
    "busca_binaria = searchBinary(\"segundo turno\")\n",
    "busca_TF = searchTF(\"segundo turno\")\n",
    "busca_TF_IDF = searchTF_IDF(\"segundo turno\")\n",
    "\n",
    "mapk(gabarito.values[0][2], busca_binaria, k=5)\n",
    "\n",
    "mapk(gabarito.values[1][2], busca_TF, k=5)\n",
    "\n",
    "mapk(gabarito.values[2][2], busca_TF_IDF, k=5)\n",
    "\n",
    "#mapk(gabarito.bm25, suaresposta.bm25, k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['segundo turno' '[1062, 1942, 2161, 2078, 2073]'\n",
      "  '[2048, 1, 2049, 2050, 4096]' '[2744, 7, 2112, 7672, 2388]'\n",
      "  '[2744, 2112, 7672, 1235, 2388]' '[2744, 2112, 7672, 2388, 2178]']\n",
      " ['lava jato' '[616, 164, 1734, 163, 6716]' '[3, 13, 15, 27, 6177]'\n",
      "  '[163, 353, 2807, 127, 359]' '[163, 353, 2807, 127, 359]'\n",
      "  '[163, 353, 2807, 127, 359]']\n",
      " ['projeto de lei' '[2853, 275, 978, 7092, 3171]'\n",
      "  '[3584, 6145, 8194, 8706, 6660]' '[7, 3942, 7017, 1250, 6942]'\n",
      "  '[2232, 6461, 2853, 3171, 3942]' '[2232, 6461, 3171, 2853, 3170]']\n",
      " ['compra de voto' '[2200, 8615, 2265, 7746, 82]'\n",
      "  '[7424, 2178, 6531, 5122, 2311]' '[3942, 7017, 5129, 2047, 748]'\n",
      "  '[7343, 7293, 6791, 3942, 2047]' '[7343, 7293, 6791, 7329, 8615]']\n",
      " ['minist\\xc3\\xa9rio p\\xc3\\xbablico' '[64, 6652, 164, 6550, 8615]'\n",
      "  '[8194, 7, 4104, 8201, 4109]' '[6798, 8018, 6244, 6965, 6550]'\n",
      "  '[6798, 8018, 6244, 6965, 6550]' '[6798, 8018, 6244, 6965, 6550]']]\n",
      "[2048, 1, 2049, 2050, 4096]\n"
     ]
    }
   ],
   "source": [
    "print gabarito.values\n",
    "print gabarito.values[0][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segundo turno,\n",
    "google: \"[1062, 1942, 2161, 2078, 2073]\",\n",
    "Binary: \"[2048, 1, 2049, 2050, 4096]\",\n",
    "TF: \"[2744, 7, 2112, 7672, 2388]\",\n",
    "TD-IDF: \"[2744, 2112, 7672, 1235, 2388]\",\n",
    "BM25: \"[2744, 2112, 7672, 2388, 2178]\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

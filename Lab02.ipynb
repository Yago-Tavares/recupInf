{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy\n",
    "filename = 'estadao_noticias_eleicao.csv'\n",
    "data = pd.read_csv(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to search with TF method \n",
    "def searchTF(query):\n",
    "    searchWords = query.split(\" \")\n",
    "    #The top five document by higher frequences \n",
    "    topFive = {}\n",
    "    for i in range(len(data.values)):\n",
    "        #Get frequence of document i\n",
    "        documentID, frequence = frequenceDocument(searchWords, data.values[i]);\n",
    "        \n",
    "        #Add document and frequence in topFive dictionary\n",
    "        if(len(topFive) < 5):\n",
    "            topFive[documentID]= frequence\n",
    "        else:\n",
    "            minKey = None\n",
    "            for j in topFive.keys():\n",
    "                if(frequence > topFive[j]):\n",
    "                    if(minKey == None or topFive[j] < topFive[minKey]):\n",
    "                        minKey = j\n",
    "            if(minKey != None):\n",
    "                topFive[documentID] = frequence;\n",
    "                del topFive[minKey]\n",
    "    \n",
    "    returnTopFive(topFive)\n",
    "\n",
    "#Function to print topFive of documents\n",
    "def returnTopFive(topFive):\n",
    "    print \"Top five documents\"\n",
    "    for document in sorted(topFive, key = topFive.get):\n",
    "        print \"DocSument: \" + str(document) + \", frequence: \" + str(topFive[document])    \n",
    "        \n",
    "#Function to calculate the frequency of query words in the document\n",
    "def frequenceDocument(query, document):\n",
    "    frequence = 0\n",
    "    if(is_nan(document[1])):\n",
    "        document[1] = \"\"\n",
    "    if(is_nan(document[2])):\n",
    "        document[2] = \"\"\n",
    "    if(is_nan(document[3])):\n",
    "        document[3] = \"\"\n",
    "    documentWords = document[1].split(\" \") + document[2].split(\" \") + document[3].split(\" \")\n",
    "    #iteração entre todas as palavras do documento\n",
    "    for word in documentWords:\n",
    "        for q in query:\n",
    "            if(q.lower() == word.lower()):\n",
    "                frequence += 1\n",
    "    \n",
    "    return document[5], frequence\n",
    "    \n",
    "#Function to verify if element 's' is nan    \n",
    "def is_nan(s):\n",
    "    try:\n",
    "        float(s)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top five documents\n",
      "Doument: 4931, frequence: 15\n",
      "Doument: 2112, frequence: 17\n",
      "Doument: 2388, frequence: 17\n",
      "Doument: 7, frequence: 27\n",
      "Doument: 2744, frequence: 31\n"
     ]
    }
   ],
   "source": [
    "searchTF(\"segundo turno\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

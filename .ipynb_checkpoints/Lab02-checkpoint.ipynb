{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy, math\n",
    "filename = 'estadao_noticias_eleicao.csv'\n",
    "data = pd.read_csv(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to search with TF method \n",
    "def searchTF(query):\n",
    "    searchWords = query.split(\" \")\n",
    "    #The top five document by higher frequences \n",
    "    topFive = {}\n",
    "    for i in range(len(data.values)):\n",
    "        #Get frequence of document i\n",
    "        documentID, frequence = frequenceTF(searchWords, data.values[i]);\n",
    "        \n",
    "        #Add document and frequence in topFive dictionary\n",
    "        if(len(topFive) < 5):\n",
    "            topFive[documentID]= frequence\n",
    "        else:\n",
    "            minKey = None\n",
    "            for j in topFive.keys():\n",
    "                if(frequence > topFive[j]):\n",
    "                    if(minKey == None or topFive[j] < topFive[minKey]):\n",
    "                        minKey = j\n",
    "            if(minKey != None):\n",
    "                topFive[documentID] = frequence;\n",
    "                del topFive[minKey]\n",
    "    \n",
    "    returnTopFiveTF(topFive)\n",
    "\n",
    "#Function to print topFive of documents\n",
    "def returnTopFiveTF(topFive):\n",
    "    print \"Top five documents\"\n",
    "    for document in sorted(topFive, key = topFive.get):\n",
    "        print \"DocSument: \" + str(document) + \", frequence: \" + str(topFive[document])    \n",
    "        \n",
    "#Function to calculate the frequency of query words in the document\n",
    "def frequenceTF(query, document):\n",
    "    frequence = 0\n",
    "    if(is_nan(document[1])):\n",
    "        document[1] = \"\"\n",
    "    if(is_nan(document[2])):\n",
    "        document[2] = \"\"\n",
    "    if(is_nan(document[3])):\n",
    "        document[3] = \"\"\n",
    "    documentWords = document[1].split(\" \") + document[2].split(\" \") + document[3].split(\" \")\n",
    "    #iteração entre todas as palavras do documento\n",
    "    for word in documentWords:\n",
    "        for q in query:\n",
    "            if(q.lower() == word.lower()):\n",
    "                frequence += 1\n",
    "    \n",
    "    return document[5], frequence\n",
    "    \n",
    "#Function to verify if element 's' is nan    \n",
    "def is_nan(s):\n",
    "    try:\n",
    "        float(s)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def searchTF_IDF(query):\n",
    "    searchWords = query.split(\" \")\n",
    "    numberOfDocs = len(data.values)\n",
    "    #The top five document by higher frequences \n",
    "    topFive = {}\n",
    "    for i in range(len(data.values)):\n",
    "        dicIDF = IDF(searchWords, data.values[i], numberOfDocs)\n",
    "        #Get frequence of document i\n",
    "        documentID, frequence = frequenceTF_IDF(searchWords, data.values[i], dicIDF);\n",
    "        \n",
    "        #Add document and frequence in topFive dictionary\n",
    "        if(len(topFive) < 5):\n",
    "            topFive[documentID]= frequence\n",
    "        else:\n",
    "            minKey = None\n",
    "            for j in topFive.keys():\n",
    "                if(frequence > topFive[j]):\n",
    "                    if(minKey == None or topFive[j] < topFive[minKey]):\n",
    "                        minKey = j\n",
    "            if(minKey != None):\n",
    "                topFive[documentID] = frequence;\n",
    "                del topFive[minKey]\n",
    "    \n",
    "    returnTopFive_IDF(topFive)\n",
    "\n",
    "def returnTopFiveTF_IDF(topFive):\n",
    "    print \"Top five documents\"\n",
    "    for document in sorted(topFive, key = topFive.get):\n",
    "        print \"DocSument: \" + str(document) + \", frequence: \" + str(topFive[document])    \n",
    "    \n",
    "def IDF(query, document, numberOfDocs):\n",
    "    dictDocsFrequence = {}\n",
    "    if(is_nan(document[1])):\n",
    "        document[1] = \" \"\n",
    "    if(is_nan(document[2])):\n",
    "        document[2] = \" \"\n",
    "    if(is_nan(document[3])):\n",
    "        document[3] = \" \"\n",
    "    documentWords = document[1].split(\" \") + document[2].split(\" \") + document[3].split(\" \")\n",
    "    #cada palavra da consulta\n",
    "    for wordQuery in query:\n",
    "        #cada Palavra no documento\n",
    "        for wordDocuments in documentWords:\n",
    "            if(wordQuery.lower() == wordDocuments.lower()):\n",
    "                if(wordQuery in dictDocsFrequence):\n",
    "                    dictDocsFrequence[wordQuery] = dictDocsFrequence[wordQuery] + 1\n",
    "                    break\n",
    "                else:\n",
    "                    dictDocsFrequence[wordQuery] = 1\n",
    "                    break\n",
    "    dictIDF = {}\n",
    "    for i in dictDocsFrequence.keys(): \n",
    "        dictIDF[i] = math.log10((numberOfDocs + 1) / dictDocsFrequence[i])\n",
    "    print dictIDF\n",
    "    return dictIDF\n",
    "\n",
    "def frequenceTF_IDF(query, document, dictIDF):\n",
    "    frequence = 0\n",
    "    if(is_nan(document[1])):\n",
    "        document[1] = \"\"\n",
    "    if(is_nan(document[2])):\n",
    "        document[2] = \"\"\n",
    "    if(is_nan(document[3])):\n",
    "        document[3] = \"\"\n",
    "    documentWords = document[1].split(\" \") + document[2].split(\" \") + document[3].split(\" \")\n",
    "    for wordQuery in query:\n",
    "        frequenceWord = 0\n",
    "        #iteração entre todas as palavras do documento\n",
    "        for wordDocument in documentWords:\n",
    "            if(wordQuery.lower() == wordDocument.lower()):\n",
    "                frequenceWord += 1\n",
    "        frequence += frequenceWord * dictIDF[wordQuery]\n",
    "        \n",
    "    return document[5], frequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'segundo': 3.9403670459856652}\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'turno'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-105-59799445b2a1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msearchTF_IDF\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"segundo turno\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-104-ca90c9c2c7c8>\u001b[0m in \u001b[0;36msearchTF_IDF\u001b[0;34m(query)\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mdicIDF\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mIDF\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msearchWords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumberOfDocs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;31m#Get frequence of document i\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mdocumentID\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrequence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfrequenceTF_IDF\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msearchWords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdicIDF\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;31m#Add document and frequence in topFive dictionary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-104-ca90c9c2c7c8>\u001b[0m in \u001b[0;36mfrequenceTF_IDF\u001b[0;34m(query, document, dictIDF)\u001b[0m\n\u001b[1;32m     70\u001b[0m             \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwordQuery\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mwordDocument\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m                 \u001b[0mfrequenceWord\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0mfrequence\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mfrequenceWord\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mdictIDF\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mwordQuery\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdocument\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrequence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'turno'"
     ]
    }
   ],
   "source": [
    "searchTF_IDF(\"segundo turno\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy, math\n",
    "filename = 'estadao_noticias_eleicao.csv'\n",
    "data = pd.read_csv(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to search with TF method \n",
    "def searchTF(query):\n",
    "    searchWords = query.split(\" \")\n",
    "    #The top five document by higher frequences \n",
    "    topFive = {}\n",
    "    for i in range(len(data.values)):\n",
    "        #Get frequence of document i\n",
    "        documentID, frequence = frequenceTF(searchWords, data.values[i]);\n",
    "        \n",
    "        #Add document and frequence in topFive dictionary\n",
    "        if(len(topFive) < 5):\n",
    "            topFive[documentID]= frequence\n",
    "        else:\n",
    "            minKey = None\n",
    "            for j in topFive.keys():\n",
    "                if(frequence > topFive[j]):\n",
    "                    if(minKey == None or topFive[j] < topFive[minKey]):\n",
    "                        minKey = j\n",
    "            if(minKey != None):\n",
    "                topFive[documentID] = frequence;\n",
    "                del topFive[minKey]\n",
    "    \n",
    "    returnTopFiveTF(topFive)\n",
    "\n",
    "#Function to print topFive of documents\n",
    "def returnTopFiveTF(topFive):\n",
    "    print \"Top five documents\"\n",
    "    for document in sorted(topFive, key = topFive.get):\n",
    "        print \"DocSument: \" + str(document) + \", frequence: \" + str(topFive[document])    \n",
    "        \n",
    "#Function to calculate the frequency of query words in the document\n",
    "def frequenceTF(query, document):\n",
    "    frequence = 0\n",
    "    if(is_nan(document[1])):\n",
    "        document[1] = \"\"\n",
    "    if(is_nan(document[2])):\n",
    "        document[2] = \"\"\n",
    "    if(is_nan(document[3])):\n",
    "        document[3] = \"\"\n",
    "    documentWords = document[1].split(\" \") + document[2].split(\" \") + document[3].split(\" \")\n",
    "    #iteração entre todas as palavras do documento\n",
    "    for word in documentWords:\n",
    "        for q in query:\n",
    "            if(q.lower() == word.lower()):\n",
    "                frequence += 1\n",
    "    \n",
    "    return document[5], frequence\n",
    "    \n",
    "#Function to verify if element 's' is nan    \n",
    "def is_nan(s):\n",
    "    try:\n",
    "        float(s)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def searchTF_IDF(query):\n",
    "    searchWords = query.split(\" \")\n",
    "    numberOfDocs = len(data.values)\n",
    "    #The top five document by higher frequences \n",
    "    topFive = {}\n",
    "    dictDocsFrequence = {}\n",
    "    for i in range(len(data.values)):\n",
    "        dictDocsFrequence = IDF(searchWords, data.values[i], dictDocsFrequence)\n",
    "    dictIDF = {}\n",
    "    for i in dictDocsFrequence.keys(): \n",
    "        dictIDF[i] = math.log10((numberOfDocs + 1) / dictDocsFrequence[i])\n",
    "    for i in range(len(data.values)):\n",
    "        #Get frequence of document i\n",
    "        documentID, frequence = frequenceTF_IDF(searchWords, data.values[i], dictIDF);\n",
    "        \n",
    "        #Add document and frequence in topFive dictionary\n",
    "        if(len(topFive) < 5):\n",
    "            topFive[documentID]= frequence\n",
    "        else:\n",
    "            minKey = None\n",
    "            for j in topFive.keys():\n",
    "                if(frequence > topFive[j]):\n",
    "                    if(minKey == None or topFive[j] < topFive[minKey]):\n",
    "                        minKey = j\n",
    "            if(minKey != None):\n",
    "                topFive[documentID] = frequence;\n",
    "                del topFive[minKey]\n",
    "    \n",
    "    returnTopFive_IDF(topFive)\n",
    "\n",
    "def returnTopFive_IDF(topFive):\n",
    "    print \"Top five documents\"\n",
    "    for document in sorted(topFive, key = topFive.get):\n",
    "        print \"DocSument: \" + str(document) + \", frequence: \" + str(topFive[document])    \n",
    "    \n",
    "def IDF(query, document, dictDocsFrequence):\n",
    "    if(is_nan(document[1])):\n",
    "        document[1] = \" \"\n",
    "    if(is_nan(document[2])):\n",
    "        document[2] = \" \"\n",
    "    if(is_nan(document[3])):\n",
    "        document[3] = \" \"\n",
    "    documentWords = document[1].split(\" \") + document[2].split(\" \") + document[3].split(\" \")\n",
    "    #cada palavra da consulta\n",
    "    for wordQuery in query:\n",
    "        #cada Palavra no documento\n",
    "        for wordDocuments in documentWords:\n",
    "            if(wordQuery.lower() == wordDocuments.lower()):\n",
    "                if(wordQuery in dictDocsFrequence):\n",
    "                    dictDocsFrequence[wordQuery] = dictDocsFrequence[wordQuery] + 1\n",
    "                    break\n",
    "                else:\n",
    "                    dictDocsFrequence[wordQuery] = 1\n",
    "                    break\n",
    "\n",
    "    return dictDocsFrequence\n",
    "\n",
    "def frequenceTF_IDF(query, document, dictIDF):\n",
    "    frequence = 0\n",
    "    if(is_nan(document[1])):\n",
    "        document[1] = \"\"\n",
    "    if(is_nan(document[2])):\n",
    "        document[2] = \"\"\n",
    "    if(is_nan(document[3])):\n",
    "        document[3] = \"\"\n",
    "    documentWords = document[1].split(\" \") + document[2].split(\" \") + document[3].split(\" \")\n",
    "    for wordQuery in query:\n",
    "        frequenceWord = 0\n",
    "        #iteração entre todas as palavras do documento\n",
    "        for wordDocument in documentWords:\n",
    "            if(wordQuery.lower() == wordDocument.lower()):\n",
    "                frequenceWord += 1\n",
    "        frequence += frequenceWord * dictIDF[wordQuery]\n",
    "        \n",
    "    return document[5], frequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AAAAAAAAAAAAAAAAA 7 1.2552725051 compra\n",
      "AAAAAAAAAAAAAAAAA 37 0.0 de\n",
      "AAAAAAAAAAAAAAAAA 0 0.954242509439 voto\n",
      "Top five documents\n",
      "DocSument: 6593, frequence: 8.78690753572\n",
      "DocSument: 173, frequence: 8.78690753572\n",
      "DocSument: 314, frequence: 8.78690753572\n",
      "DocSument: 316, frequence: 8.78690753572\n",
      "DocSument: 7293, frequence: 9.74115004516\n"
     ]
    }
   ],
   "source": [
    "#searchTF(\"compra de voto\")\n",
    "searchTF_IDF(\"compra de voto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictIDF {'compra': 1.255272505103306, 'voto': 0.9542425094393249, 'de': 0.0}\n",
    "DocSument: 6593, frequence: 8.78690753572"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
